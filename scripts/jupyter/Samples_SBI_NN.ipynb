{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvasist/miniconda3/envs/petitRT/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "# import os\n",
    "# os.environ[\"pRT_input_data_path\"] = \"/home/mvasist/pRT/input_data\"\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import h5py\n",
    "import glob\n",
    "\n",
    "import pymultinest\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "from petitRADTRANS import Radtrans\n",
    "from petitRADTRANS import nat_cst as nc \n",
    "from petitRADTRANS.retrieval.parameter import Parameter\n",
    "from petitRADTRANS.retrieval.models import emission_model_diseq\n",
    "\n",
    "from sbi.inference import SNRE_A, SNRE, prepare_for_sbi, simulate_for_sbi, SNPE_A\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "from sbi import utils as utils\n",
    "from sbi.types import Array, OneOrMore, ScalarFloat\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "from vit_pytorch.efficient import ViT\n",
    "from linformer import Linformer\n",
    "from vit_pytorch import ViT as ViT_modified\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvasist/miniconda3/envs/petitRT/lib/python3.7/site-packages/sbi-0.17.0-py3.7.egg/sbi/utils/torchutils.py:36: UserWarning: Device cuda not available, falling back to CPU.\n",
      "  warnings.warn(f\"Device {device} not available, falling back to CPU.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoxUniform(Uniform(low: torch.Size([13]), high: torch.Size([13])), 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prior= utils.BoxUniform(low=torch.tensor([0.1, -1.5, -6.0, -3.5, -3.5, 1.0, 5.0, 1.05, 2.0, 0.7, 300.0, 0., 0., 0.,\\\n",
    "#                                   1., 0. ]), \\\n",
    "#                       high=torch.tensor([1.6, 1.5, 3.0, 4.5, 4.5, 11.0, 13.0, 3.0, 5.5, 2.0, 2300.0, 1., 1., 1.,\\\n",
    "#                                       2., 1. ]))\n",
    "\n",
    "Prior= utils.BoxUniform(low=torch.tensor([0.1, -1.5, -6.0, -3.5, -3.5, 2.0, 0.7, 300.0, 0., 0., 0.,\\\n",
    "                                  1., 0. ]), \\\n",
    "                      high=torch.tensor([1.6, 1.5, 3.0, 4.5, 4.5, 5.5, 2.0, 2300.0, 1., 1., 1.,\\\n",
    "                                      2., 1. ]), device='cuda')\n",
    "Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = SNPE_A(prior= Prior, device= 'cpu', classifier='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mvasist/scripts_new'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from test hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('/home/mvasist/scripts_new/datasets/dataset/_/test.h5', 'r') as f: \n",
    "#     spec = torch.Tensor(f.get('spectra'))\n",
    "#     th = torch.Tensor(f.get('theta'))\n",
    "#     indices = torch.tensor([0,1,2,3,4,8,9,10,11,12,13,14,15])\n",
    "#     th_reduced = torch.index_select(th, 1, indices)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path = '/home/mvasist/simulations_new/16_params/'\n",
    "\n",
    "# ptX = []\n",
    "# T = []\n",
    "\n",
    "# for k in range(1, 1001):   \n",
    "#     print(k)\n",
    "#     if (322<=k<= 336): \n",
    "#         continue\n",
    "\n",
    "#     dfptX= pd.read_csv(path+ 'X_5Msim_'+ str(k) + '.csv', engine ='python', header=None, index_col=0)  #, low_memory = False)\n",
    "#     dfT= pd.read_csv(path+ 'T_5Msim_'+ str(k) + '.csv', engine ='python', header=None, index_col=0)  #, low_memory = False)\n",
    "    \n",
    "#     ptX.append(dfptX)\n",
    "#     T.append(dfT)\n",
    "    \n",
    "# comb_np_array_ptX = np.vstack(ptX)\n",
    "# ptx = torch.from_numpy(comb_np_array_ptX).type(torch.float32)\n",
    "# comb_np_array_T = np.vstack(T)\n",
    "# th = torch.from_numpy(comb_np_array_T).type(torch.float32)\n",
    "\n",
    "# x = ptx[:,947*2:]\n",
    "# indx = (~torch.isnan(x)).sum(axis = 1) == 947\n",
    "# x = x[indx, :] #deleting rows with nan values\n",
    "# #     p = ptx[:,0:947]\n",
    "# #     t = ptx[:,947:947*2]\n",
    "\n",
    "# th = th[indx,:] #deleting rows with nan values\n",
    "# indices = torch.tensor([0,1,2,3,4,8,9,10,11,12,13,14,15])\n",
    "# th_reduced = torch.index_select(th, 1, indices)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2685664/2762707207.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/mvasist/scripts_new/datasets/dataset/_/onehot/*.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/petitRT/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/petitRT/lib/python3.7/site-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36m_e\u001b[0;34m(self, name, lcpl)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mcoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCSET_ASCII\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "T=[]\n",
    "for i, file_path in enumerate(glob.iglob('/home/mvasist/scripts_new/datasets/dataset/_/onehot/*.h5')):\n",
    "    print(i)\n",
    "    with h5py.File(file_path, 'r') as h5_file:\n",
    "        spec = h5_file['data'][()]\n",
    "        T.append(spec[:100, 0, :13])\n",
    "        X.append(spec[:100, 0, 13:])\n",
    "            \n",
    "comb_np_array_x = np.vstack(X)\n",
    "x = torch.from_numpy(comb_np_array_x).type(torch.float32)\n",
    "comb_np_array_T = np.vstack(T)\n",
    "th_reduced = torch.from_numpy(comb_np_array_T).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = inference.append_simulations(th_reduced.to(device), x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_estimator = inference.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wlen = torch.load('wlen.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = torch.load('/home/mvasist/scripts_new/observation/obs.pt') \n",
    "\n",
    "start = time.time()\n",
    "sampls= 10000 #200000\n",
    "\n",
    "samples = posterior.sample((sampls,), x=observation)\n",
    "log_probability = posterior.log_prob(samples, x= observation)\n",
    "\n",
    "end= time.time()\n",
    "time_taken = (end-start)/3600  #hrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the samples file\n",
    "\n",
    "df_samples = pd.DataFrame(samples.numpy())\n",
    "df_samples.to_csv('/home/mvasist/samples_new/samples_e28.csv',mode='a', header=False)\n",
    "\n",
    "df_lnprob = pd.DataFrame(log_probability.numpy())\n",
    "df_lnprob.to_csv('/home/mvasist/samples_new/lnprob_e28.csv',mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = torch.load('/home/mvasist/scripts_new/observation/obs.pt') \n",
    "\n",
    "observation.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a52cde6f5da16726e1e0474ad78e23286cb43c3a3728cb0a197cc2311bc1810"
  },
  "kernelspec": {
   "display_name": "Python [conda env:petitRT]",
   "language": "python",
   "name": "conda-env-petitRT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
